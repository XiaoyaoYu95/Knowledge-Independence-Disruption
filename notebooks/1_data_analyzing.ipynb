{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9fdf7d",
   "metadata": {},
   "source": [
    "# Data analyses\n",
    "1. Regression analysis\n",
    "2. Mediation analysis\n",
    "3. PSM analysis\n",
    "\n",
    "All the above analyses use the same dataframe merged from the processed data. You can find download this merged data from "PaperID_KI2-Dopen_nok_control.pickle" and store it in the path \"data/processed/\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331c448",
   "metadata": {},
   "source": [
    "## 1. Normalized ordinary-least-squares (OLS) regression\n",
    "To analyze the relationships between scientific disruption and various covariates, we employ normalized ordinary least squares (OLS) regression models. This approach allows us to evaluate whether $\\rm{KI}$ has a dominant effect on disruption. The regression models include the following covariates: focal paper properties (impact $C_5$, discipline, and publication year), reference properties (novelty, reference count, average age, average impact $C_5$, and average disruption), as well as team properties (size, geographic distance, and collaboration freshness). All numerical variables are standardized by $Z$-score normalization to ensure comparability of effect coefficients across models. We start with a model that does not control for any covariates other than fixing discipline and publication year (eq.2). Then, we control for each of the following covariates separately (eq.3): focal paper's impact ($C_5$), novelty, reference count, reference age, reference impact ($C_5$), reference disruption, team size, team distance, and team freshness. Finally, we consider a model that accounts for all those covariates (eq.4).\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    D &= b_0 + a_0{\\rm{KI}} + c_{0}F, \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad (2) \\\\\n",
    "    D &= b_0 + a_0{\\rm{KI}} + a_{i}C_i + c_{0}F, \\quad\\quad\\quad\\quad\\quad (3) \\\\\n",
    "    D &= b_0 + a_0{\\rm{KI}} + \\sum\\nolimits_{i=1}^{9}a_{i}C_i + c_{0}F. \\quad\\quad (4)\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb892e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "from collections import defaultdict\n",
    "\n",
    "pre_path = os.path.abspath(r\"..\")\n",
    "sys.path.insert(1, os.path.join(pre_path, 'src'))\n",
    "from utils import load_data, rank, rank_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122832dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "data_type = 'nor'      # 'raw' or 'nor': normalized or raw data\n",
    "DC_type = 'Dopen_nok'  # 'Dopen_nok', 'Dopen', 'D5_nok', 'D5'\n",
    "KI_type = 'KI2'        # 'KI2', 'KI2_frac', 'KI2_adj', 'KI2_adj_frac'\n",
    "file_path = '%s/data/processed/PaperID_%s-%s_merged.pickle'%(pre_path,KI_type,DC_type)\n",
    "\n",
    "# Define dependent and independent variables, fixed effects, and control variables\n",
    "dependent_var = DC_type\n",
    "independent_var = KI_type\n",
    "fixed_effects = ['Year','Field']\n",
    "# control all covirate variables, one can add or remove variables as needed\n",
    "control_vars = ['log_C5','Novelty_90pct','reference_Count','reference_Age','reference_C5','reference_'+DC_type,'Team_Size','Team_Distance','Team_Freshness']\n",
    "\n",
    "\n",
    "# Define all variables to be used in the model\n",
    "all_vars = [dependent_var,independent_var] + fixed_effects + control_vars\n",
    "# load data\n",
    "df = load_data(file_path, data_type, all_vars)\n",
    "\n",
    "# Define the model\n",
    "y, X = dmatrices((' ~ '.join(all_vars[:2])) + '+' + (' + '.join(all_vars[2:])), data=df, return_type='dataframe')\n",
    "model = sm.OLS(y, X)    # Describe model\n",
    "res = model.fit()       # Fit model\n",
    "print(res.summary())    # Summarize model\n",
    "# Save the results\n",
    "with open('%s/results/results_for_tables/Regression_Analysis_Results/Regression_summary_%s_%s_%s.latex'%(pre_path,KI_type,DC_type,data_type), 'w') as fh:\n",
    "    fh.write(res.summary().as_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe4bd4c",
   "metadata": {},
   "source": [
    "## 2. Mediation analysis\n",
    "Here we utilize the model-based mediation framework, comprising two parametric regression models: Outcome Model (eq.5) formulates the relation between the outcome $Y$ and the target variable $X$, as well as the mediator $M$, with covariates $C$ controlled. On the other hand, the Mediator Model (eq.6) formulates the relation between the mediator $M$ and the target variable $X$, also controlling for covariates $C$. The indirect effect (ACME) is defined as the product of the coefficient $\\beta_1$ of $X$ in model (eq.6) and the coefficient $\\theta_2$ of $M$ in model (eq.5). This represents the portion of $X$'s effect on $Y$ mediated through $M$. The direct effect (ADE) is defined as the coefficient $\\theta_1$ of $X$ in model (eq.5), capturing the direct relationship between $X$ and $Y$, independent of $M$. The total effect (TE) is defined as the sum of the indirect effect (ACME) and direct effect (ADE). \n",
    "In all conducted mediation analyses, we standardize the numerical variables by $Z$-score normalization to ensure comparability of effect coefficients across models, with discipline and publication year controlled. \n",
    "$$\n",
    "\\begin{aligned}\n",
    "    Y &= \\theta_{0} + \\theta_{1}X + \\theta_{2}M + \\theta_{3}C, \\quad (5)\\\\\n",
    "    M &= \\beta_{0} + \\beta_{1}X + \\beta_{2}C. \\quad\\quad\\quad\\quad (6)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_value_stars(pv):\n",
    "    stars = ''\n",
    "    if  pv< 0.05 and pv>= 0.01:\n",
    "        stars = '*'\n",
    "    if  pv< 0.01 and pv>= 0.001:\n",
    "        stars = '**'\n",
    "    if  pv< 0.001:\n",
    "        stars = '***'\n",
    "    return stars\n",
    "    \n",
    "    \n",
    "def summary_sub(effect_list, smry, mediator, effect_name):\n",
    "    smry.loc[mediator, effect_name] = np.median(effect_list) # Estimate\n",
    "    \n",
    "    Statistic_T, P_value = stats.ttest_1samp(effect_list, 0) # Statistic T, P-value\n",
    "    smry.loc[mediator, effect_name+\"_PV\"] = P_value # P-value\n",
    "    smry.loc[mediator, effect_name+\"_Stars\"] = P_value_stars(P_value) # Significance stars\n",
    "    \n",
    "    Lower_CI_bound, Upper_CI_bound = np.percentile(effect_list, [2.5, 97.5]) # Lower CI bound, Upper CI bound\n",
    "    smry.loc[mediator, effect_name+\"_SE\"] = (Upper_CI_bound-Lower_CI_bound)/2 # SE\n",
    "    \n",
    "    return smry\n",
    "\n",
    "\n",
    "def summary(Mediator_list, indirect_effects, direct_effects, total_effects):\n",
    "    \"\"\"\n",
    "    Provide a summary of a mediation analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    columns = [\"Mediator\", \"ACME\", \"ACME_PV\", \"ACME_Stars\", \"ACME_SE\", \"ADE\", \"ADE_PV\", \"ADE_Stars\", \"ADE_SE\", \"TE\", \"TE_PV\", \"TE_Stars\", \"TE_SE\"]\n",
    "    index = Mediator_list\n",
    "    smry = pd.DataFrame(columns=columns, index=index)\n",
    "\n",
    "    for Mediator in Mediator_list:\n",
    "        smry = summary_sub(indirect_effects[Mediator], smry, Mediator, \"ACME\")\n",
    "        smry = summary_sub(direct_effects[Mediator], smry, Mediator, \"ADE\")\n",
    "        smry = summary_sub(total_effects[Mediator], smry, Mediator, \"TE\")\n",
    "    smry = smry.apply(pd.to_numeric, errors='coerce')\n",
    "    return smry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ac2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "data_type = 'nor'    # 'raw' or 'nor'\n",
    "iter_num = 1000      # Number of iterations for bootstrapping\n",
    "\n",
    "DC_type = 'Dopen_nok'  # 'Dopen_nok', 'Dopen', 'D5_nok', 'D5'\n",
    "KI_type = 'KI2'        # 'KI2', 'KI2_frac', 'KI2_adj', 'KI2_adj_frac'\n",
    "file_path = '%s/data/processed/PaperID_%s-%s_merged.pickle'%(pre_path,KI_type,DC_type)\n",
    "\n",
    "# Define dependent and independent variables, fixed effects, and control variables\n",
    "dependent_var = DC_type\n",
    "independent_vars = ['reference_'+DC_type,'Team_Size','Team_Distance','Team_Freshness','Citation_percentile']\n",
    "Mediating_vars = [KI_type,'Novelty_90pct','reference_Count','reference_Age','reference_C5','Team_Size','Team_Distance','Team_Freshness']\n",
    "fixed_effects = ['Year','Field']\n",
    "###################\n",
    "for independent_var in independent_vars: # Due to the time-consuming nature of the analysis, we suggest to analyze the variable one by one.\n",
    "    # Define the base equation for the regression model\n",
    "    base_eq = \" ~ %s + Year + Field\"%(independent_var)\n",
    "    Mediator_list = [M for M in Mediating_vars if M != independent_var] # Exclude the independent variable from the mediators list\n",
    "    \n",
    "    all_vars = [dependent_var,independent_var] + Mediator_list + fixed_effects\n",
    "    DF = load_data(file_path, data_type, all_vars)\n",
    "\n",
    "    indirect_effects = defaultdict(list)\n",
    "    direct_effects = defaultdict(list)\n",
    "    total_effects = defaultdict(list)\n",
    "    for iter in range(iter_num):\n",
    "        boot_sample_indx = np.random.randint(len(DF), size=len(DF))\n",
    "        df_boot_sample = DF.iloc[boot_sample_indx, :]\n",
    "        \n",
    "        # for each possible mediator, fit the outcome and mediator models, and calculate effects\n",
    "        for Mediator in Mediator_list:\n",
    "            # fit the outcome model\n",
    "            Outcome_eq = dependent_var + base_eq + ' + ' + Mediator\n",
    "            reg = sm.OLS.from_formula(Outcome_eq, df_boot_sample).fit()\n",
    "\n",
    "            # fit the mediator model\n",
    "            Mediator_eq = Mediator + base_eq\n",
    "            med = sm.OLS.from_formula(Mediator_eq, df_boot_sample).fit()\n",
    "                \n",
    "            # calculate the direct, indirect, and total effects\n",
    "            direct = reg.params[independent_var]\n",
    "            indirect = med.params[independent_var] * reg.params[Mediator]\n",
    "            total = direct + indirect\n",
    "            \n",
    "            indirect_effects[Mediator].append(indirect)\n",
    "            direct_effects[Mediator].append(direct)\n",
    "            total_effects[Mediator].append(total)\n",
    "    summary(Mediator_list, indirect_effects, direct_effects, total_effects).to_csv('%s/results/results_for_tables/Mediation_Analysis_Results/Mediation_Analysis_%s_%s_%s_%s.csv'%(pre_path,KI_type,DC_type,data_type,independent_var),encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2131aee",
   "metadata": {},
   "source": [
    "## 3. Propensity Score Matching (PSM) analysis\n",
    "The procedure involves the following steps. We first categorize papers into the treated group and controlled group according to treatment size ($\\rm{KI}$). Subsequently, we estimate the propensity score for each paper by fitting a generalized linear model where the treatment size is the dependent variable. The model includes the following covariates: focal paper properties (impact $C_5$ and publication year), reference properties (novelty, reference count, average age, average impact $C_5$, and average disruption), and team properties (size, geographic distance, and collaboration freshness). For each paper $i$ in the controlled group, a counterpart from the treated group with a similar propensity score is matched. This matching ensures a balanced distribution of covariates across the two groups, effectively mimicking the conditions of a randomized controlled trial. After identifying $m$ matched pairs of papers, denoted as $M$, we calculate the Average Treatment Effect on the Treated as $\\text{ATT}=\\frac{1}{m}\\sum_{i\\in M}(Y^{1}_{i}-Y^{0}_{i})$, where $Y^{1}_{i}$ is the outcome (scientific disruption) for the treated paper and $Y^{0}_{i}$ is the outcome for the control paper. To enhance the robustness of PSM results, we perform multiple experiments for different pairs of treated and control groups. This will produce a matrix of ATT values, providing a comprehensive and nuanced view of the effect size of $\\rm{KI}$ on scientific disruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c802e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from psmpy import PsmPy\n",
    "from psmpy.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df69d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "iter_num = 1000      # Number of iterations for bootstrapping\n",
    "\n",
    "DC_type = 'Dopen_nok'  # 'Dopen_nok', 'Dopen', 'D5_nok', 'D5'\n",
    "KI_type = 'KI2'        # 'KI2', 'KI2_frac', 'KI2_adj', 'KI2_adj_frac'\n",
    "file_path = '%s/data/processed/PaperID_%s-%s_merged.pickle'%(pre_path,KI_type,DC_type)\n",
    "\n",
    "all_vars =[KI_type,DC_type,'Year','Field','C5','Novelty_90pct','reference_Count','reference_Age','reference_C5','reference_'+DC_type,'Team_Size','Team_Distance','Team_Freshness']\n",
    "Treatment_var = KI_type\n",
    "Target_var = DC_type\n",
    "Exclude_vars = ['Field']\n",
    "\n",
    "# Define the regression type and treatment effect type\n",
    "data_type = 'raw'       # data_type: raw or normalized\n",
    "regression_type = 'glm' # regression_type: glm or logit\n",
    "treat_effect_type='ATT' # treat_effect_type: ATT or ATC\n",
    "\n",
    "# Load the data\n",
    "\n",
    "df_all = load_data(file_path, data_type, all_vars)\n",
    "\n",
    "bin_rank_list = [0,5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100]\n",
    "label_rank_list = [2.5,7.5,12.5,17.5,22.5,27.5,32.5,37.5,42.5,47.5,52.5,57.5,62.5,67.5,72.5,77.5,82.5,87.5,92.5,97.5]\n",
    "# binning the rank of 'KI_type' and 'DC_type'\n",
    "df_all[DC_type] = rank(df_all[DC_type].tolist())\n",
    "df_all[KI_type] = rank_bin(df_all[KI_type].tolist(),bin_rank_list,label_rank_list)\n",
    "# convert 'KI_type' to numeric\n",
    "df_all[KI_type] = pd.to_numeric(df_all[KI_type])\n",
    "\n",
    "treatment_size_list = sorted(list(df_all[Treatment_var].drop_duplicates()))\n",
    "\n",
    "for control_size in treatment_size_list:\n",
    "    print('The baseline:',control_size)\n",
    "    data_effect_size = []\n",
    "    for treatment_size in treatment_size_list:\n",
    "        if treatment_size == control_size:  # if the treatment size is equal to the control size, skip\n",
    "            data_effect_size.append([treatment_size, 0, treat_effect_type, \n",
    "                        0, 1, # t test: Statistic T, P value\n",
    "                        0, 0])\n",
    "        else:\n",
    "            # filter the dataframe for the current treatment and control sizes\n",
    "            df = df_all[df_all[Treatment_var].isin([control_size, treatment_size])]\n",
    "\n",
    "            # PSM model setup\n",
    "            psm = PsmPy(df, treatment=KI_type, treatment_size=treatment_size, \n",
    "                control_size=control_size, indx='paper_id', exclude = Exclude_vars, target=Target_var)\n",
    "            \n",
    "            # Fit the propensity score model\n",
    "            if regression_type == 'glm':\n",
    "                psm.glm_binom_ps(balance = True)\n",
    "            elif regression_type == 'logit':\n",
    "                psm.logistic_ps(balance = True)\n",
    "            \n",
    "            # match the treatment and control groups by KNN matching\n",
    "            psm.knn_matched(matcher='propensity_score', treat_effect_type=treat_effect_type, knn_neighbors=2, replacement=True, caliper=None, drop_unmatched=True) # matcher='propensity_score' or 'propensity_logit'\n",
    "            # calculate the effect size, psm.ATT_ATC is modified to return custom form of results\n",
    "            psm.ATT_ATC(data_effect_size, treat_effect_type=treat_effect_type, ci='boostrap', n_rep=iter_num)\n",
    "    \n",
    "    effect_size = pd.DataFrame(data_effect_size, columns=['Treatment Size', 'Effect Size','Effect Type', \n",
    "                                                        'Statistic T', 'P value', 'CI lower', 'CI upper'])\n",
    "    effect_size_ATT = effect_size[effect_size['Effect Type'] == treat_effect_type]\n",
    "    effect_size_ATT.to_csv('%s/results/results_for_tables/PSM_Analysis_Results/ALL_%s_%s_%s.csv'%(pre_path,control_size,treat_effect_type,regression_type),encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
